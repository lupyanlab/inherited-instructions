---
title: Teams of complementary problem solvers outperform equally skilled individuals
output:
  bookdown::pdf_document2:
    toc: false
  bookdown::html_document2: {}
---
```{r inherited-diversity-config, include=FALSE}
library(knitr)
library(crotchet)
opts_chunk$set(echo=FALSE, cache=TRUE, message=FALSE,
               fig.height=4, fig.width=4)
chunks_dir <- "R"
read_chunk(file.path(chunks_dir, "inherited-diversity.R"))
read_graphviz_chunk("team-structures", package = "gems",
                    new_name = "gems-team-strategies")
```
```{r inherited-diversity}
```

# Introduction {-}

People can work together in teams to solve all sorts of problems. What is the
impact of teamwork on the problem solving abilities of the people in the team?
The purpose of this research was to test the conditions under which teamwork
might improve individual problem solving ability.

There are many ways to measure the effectiveness of teamwork. A common method
is to compare the performance of teams to individuals working alone. When
compared in this way, studies have often failed to find any evidence that
teamwork provides an improvement over individual problem solving.

One of the reasons teamwork is reflected rather poorly in the experimental
literature may be due to limits on experimental methods. In order to conduct an
experiment in which both teams and individuals are administered the same task,
many tasks are necessarily excluded because they can not be equally attempted
using both teams and individuals. To use a clear example: if the problem
solving task required moving heavy objects, teamwork has clear advantages, but
no one would be surprised by these results.

Teams can clearly solve many problems that are insurmountable for individuals.
But when both teams and individuals attempt tasks that individuals can complete
alone, teamwork is rarely found to be an improvement over individual
performance.

A notable exception to this trend was a study by @Bahrami:2010jl who found
that two heads were better than one in a perceptual judgment task. In the
task, participants searched for an oddball target and responded with a
binary judgment corresponding to which of two displays contained the
target. If the two participants in each team disagreed about which display
contained the target, they were allowed to make a joint decision. Because
the participants made both individual and team responses on each trial,
the researchers were able to compare the performance of the team to the
performance of best individual in each team. The results showed a clear
benefit to teamwork over what was would have been achieved by the
best individual working alone.

Teamwork has been shown to improve performance on search tasks.

A difficulty that arises when comparing experiments done on teamwork
is in how to properly control for time. The typical approach is to control
for **calendar hours**. For example, teams and individuals are both given
an hour to complete the same task. However, controlling for calendar hours does
not scale with team size. Individuals and teams are both given an hour,
regardless of the size of the team.

# Methods {-}

```{r methods}
```

## Materials {-}

### Gabors {-}

We created `r methods$n_gabors_in_landscape` gabor patches that varied in
orientation and spatial frequency. A sample of the space is shown in Fig.
\@ref(fig:gabors). Orientations were sampled at regular intervals from
`r methods$min_ori`° to `r methods$max_ori`°. Spatial frequencies were sampled at
geometric intervals from `r methods$min_sf` cycles/pixel to `r methods$max_sf`
cycles/pixel. A geometric progression was used because high spatial frequencies
are harder to distinguish than low spatial frequencies. To make spatial frequency
a more perceptually constant dimension, we expanded the distances between
high spatial frequency stimuli using a logarithmic transformation.

(ref:gabors) Sampled space of possible gabor patches. Gabor patches varied
in orientation and spatial frequency.

```{r gabors, fig.cap="(ref:gabors)"}
draw_image("SimpleHillGems", package = "gems")
```

### Solution landscapes {-}

The value of each gem was determined by its orientation and spatial
frequency, which can be visualized as a point on a three dimensional landscape,
where the height of the landscape is the value of the gem. There were two different training
landscapes, and one test landscape. The training landscapes were constructed so
that the value of a gem was determined completely by one dimension (either
orientation or spatial frequency) and not affected by the other dimension.
Values in the test landscape were determined by both orientation and spatial
frequency. The training and test landscapes are shown in Fig.
\@ref(fig:landscapes).

```{r landscapes, fig.width=8}
data("OrientationBias")
data("SpatialFrequencyBias")
data("SimpleHill")

lattice::trellis.par.set("axis.line",list(col=NA,lty=1,lwd=1))

gridExtra::grid.arrange(
  lattice::wireframe(score ~ x * y, data = OrientationBias, xlab = "ori", ylab = "sf", main = "Orientation bias", cuts = 10),
  lattice::wireframe(score ~ x * y, data = SpatialFrequencyBias, xlab = "ori", ylab = "sf", main = "Spatial frequency bias"),
  lattice::wireframe(score ~ x * y, data = SimpleHill, xlab = "ori", ylab = "sf", main = "Simple hill"),
  nrow = 1
)
```

## Procedure {-}

Participants were told they would play a computer game where they 
play as a space explorer who travels to another planet to collect
precious gems. The goal of the game is to discover which gems
are scored the highest.

Participants were randomly assigned to one of two training conditions. In the
orientation condition, participants were told that the value of each gem
was determined by the orientation of the stripes. In the bar width condition,
they were told the value was determined by the width of the bars.

```{r training, fig.width=10, fig.height=4}
gridExtra::grid.arrange(
  read_image("training_orientation", package = "gems"),
  read_image("training_spatial_frequency", package = "gems"),
  nrow = 1
)
```

Participants completed a block of 30 training trials, followed by four
blocks of 40 test trials. There were two differences between training
and test trials: participants received additional feedback
on training trials, and participants traversed different solution
landscapes on training and test trials.

The additional feedback for training trials was that after each
response, the values of all gabors, not just the one selected, were
shown. Participants also had to select the most valuable gabor in each
display to continue to the next trial.

In the training trials, participants traversed
a training landscape according to their instructions condition. Participants
who received instructions to pay attention to orientation completed the
orientation bias landscape, and participants told to pay attention to bar width
completed the spatial frequency bias landscape.

For the four test blocks, all participants traversed the same simple hill
landscape. First generation participants started at the origin for all four
test blocks, and tried to find the most valuable gems in 40 trials. Second
generation participants started each test block at the location of a first
generation participant at trial 20.

# Results {-}

```{r results}
```

## Training {-}

```{r gems-training, fig.width=8, fig.height=8}
data("OrientationBias")
data("SpatialFrequencyBias")

orientation_bias <- wireframe(score ~ x * y, xlab = "ori", ylab = "sf", data = OrientationBias)
spatial_frequency_bias <- wireframe(score ~ x * y, xlab = "ori", ylab = "sf", data = SpatialFrequencyBias)

OrientationTraining <- Gems %>%
  filter(instructions == "orientation", landscape_name == "OrientationBias")
SpatialFrequencyTraining <- Gems %>%
  filter(instructions == "spatial_frequency", landscape_name == "SpatialFrequencyBias")

training_plot <- ggplot() +
  aes(x = current_x, y = current_y, xend = selected_x, yend = selected_y, group = subj_id) +
  geom_segment() +
  annotate("point", x = 5, y = 5, shape = 4) +
  annotate("point", x = 50, y = 50, shape = 4) +
  t_$theme

gridExtra::grid.arrange(
  orientation_bias,
  (training_plot %+% OrientationTraining) +
    aes(color = subj_id) +
    ggtitle("Orientation Training"),
  spatial_frequency_bias,
  (training_plot %+% SpatialFrequencyTraining) +
    aes(color = subj_id) +
    ggtitle("Spatial Frequency Training"),
  nrow = 2
)
```

## Test {-}

```{r gems-scores}
data("")
GemsScores <- Gems %>%
  group_by(instructions, training, landscape_ix, trial) %>%
  summarize(score = mean(score)) %>%
  ungroup()

ggplot(Gems) +
  aes(trial, score, color = instructions) +
  geom_line(aes(group = interaction(subj_id, landscape_ix)), size = 0.2) +
  geom_line(stat = "summary", fun.y = "mean", size = 2) +
  facet_wrap("training_label", scales = "free_x") +
  t_$theme +
  theme(legend.position = "bottom")
```

```{r gems-test, fig.width=8, fig.height=8}
data("SimpleHill")
simple_hill <- wireframe(score ~ x * y, data = SimpleHill, xlab = "Orientation", ylab = "Spatial frequency")

GemsTest <- filter(Gems, training == "test")
test_plot <- (training_plot %+% GemsTest) +
  aes(color = instructions) +
  facet_wrap("landscape_ix", nrow = 1) +
  theme(legend.position = "bottom")

gridExtra::grid.arrange(simple_hill, test_plot, nrow = 2)
```

# Discussion {-}
