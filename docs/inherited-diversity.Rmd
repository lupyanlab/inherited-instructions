---
title: Complementary problem solving in diachronic collaboration
bibliography: references.bib
output:
  bookdown::pdf_document2:
    toc: false
  bookdown::html_document2: {}
---
```{r inherited-diversity-config, include=FALSE}
library(knitr)
library(kableExtra)
opts_chunk$set(echo=FALSE, cache=TRUE, message=FALSE,
               fig.height=4, fig.width=4)
chunks_dir <- "R"
read_chunk(file.path(chunks_dir, "inherited-diversity.R"))

library(crotchet)
read_graphviz_chunk("team-structures", package = "gems",
                    new_name = "gems-team-strategies")
```
```{r inherited-diversity}
```

# Introduction {-}

One of the fundamental processes in cultural evolution is the transmission of
problem solving knowledge from one generation to the next. Cultural
transmission is notoriously imperfect compared to, e.g., genetic transmission.
Yet the human ability to transmit cultural information far exceeds the
abilities of any non-human animals. Humans have evolved a number of abilities
that improve the success of cultural transmission, including teaching,
language, and other social learning abilities. These abilities enable the high
fidelity reproduction of innovations over generations.

A consequence of our system of cultural inheritance is that problem solvers
rarely have to start from scratch when solving new problems. Instead, they can
start with solutions inherited from a previous generation. Does inheritance
influence future problem solving?

There are many ways to measure the effectiveness of teamwork. A common method
is to compare the performance of teams to individuals working alone. When
compared in this way, studies have often failed to find any evidence that
teamwork provides an improvement over individual problem solving.

One of the reasons teamwork is reflected rather poorly in the experimental
literature may be due to limits on experimental methods. In order to conduct an
experiment in which both teams and individuals are administered the same task,
many tasks are necessarily excluded because they can not be equally attempted
using both teams and individuals. To use a clear example: if the problem
solving task required moving heavy objects, teamwork has clear advantages, but
no one would be surprised by these results.

Teams can clearly solve many problems that are insurmountable for individuals.
But when both teams and individuals attempt tasks that individuals can complete
alone, teamwork is rarely found to be an improvement over individual
performance.

A notable exception to this trend was a study by @Bahrami:2010jl who found
that two heads were better than one in a perceptual judgment task. In the
task, participants searched for an oddball target and responded with a
binary judgment corresponding to which of two displays contained the
target. If the two participants in each team disagreed about which display
contained the target, they were allowed to make a joint decision. Because
the participants made both individual and team responses on each trial,
the researchers were able to compare the performance of the team to the
performance of best individual in each team. The results showed a clear
benefit to teamwork over what was would have been achieved by the
best individual working alone.

Teamwork has been shown to improve performance on search tasks.

A difficulty that arises when comparing experiments done on teamwork
is in how to properly control for time. The typical approach is to control
for **calendar hours**. For example, teams and individuals are both given
an hour to complete the same task. However, controlling for calendar hours does
not scale with team size. Individuals and teams are both given an hour,
regardless of the size of the team.

# Methods {-}

```{r methods}
```

Participants completed a perceptual discrimination task where they were
presented displays of gabor patches that varied in orientation and
spatial frequency. We asked them to think of the gabor patches as 
"gems" on a foreign planet, and their job was to figure out which
gems were more valuable than others.

The value of each gem was determined by the orientation and spatial frequency
of the gabor patch stimuli. The space of possible gems and their associated
values can be visualized as a three dimensional landscape. As participants
selected gems across trials, they effectively explored different parts
of the landscape, looking for the highest peaks in the landscape, corresponding
to the most valuable gems.

The six gabors presented on each trial were sampled within a certain radius of
the gabor selected on the previous trial. As a result, in order to find the
most valuable gems, participants had to move through the stimulus space
in incremental steps.

Participants were trained to pay attention to either the orientation or the bar
width of the gems. They read instructions to pay attention to
either the orientation or the bar width, and they also completed 30 trials
on a training landscape that was designed to value one stimulus dimension but
not the other. The training procedure is described below.

Participants were also assigned to the first or second generation.
First generation participants started at the origin on each landscape.
Second generation participants inherited the location on the landscape of the
gem selected by a first generation participant after 20 trials. There was no
interaction between first and second generation participants other than that
second generation participants started each landscape off in a different part
of the landscape than their predecessors.

In our analyses, we were interested in a comparison of three types
of problem solving strategies (Fig. \@ref(fig:gems-team-strategies)). Congruent
teams were made of participants trained to pay attention to the same stimulus
dimension---either orientation or bar width. Complementary teams were made of
participants trained on different stimulus dimensions. As a control, we also
compared the performance of individuals trained on a single dimension who
completed the same total number of trials on their own.

(ref:gems-team-strategies) Problem solving strategies. Participants were
trained to pay attention to either orientation or bar width and assigned to
generations. First generation participants completed the task as isolated
individuals. Second generation participants were assigned to inherit from
a first generation participant.

```{r gems-team-strategies, engine="dot", out.width="50%", fig.cap="(ref:gems-team-strategies)"}
```

## Materials {-}

### Gabors {-}

We created `r methods$n_gabors_in_landscape` gabor patches that varied in
orientation and spatial frequency. A sample of the space is shown in Fig.
\@ref(fig:gabors). Orientations were sampled at regular intervals from
`r methods$min_ori`° to `r methods$max_ori`°. Spatial frequencies were sampled 
at geometric intervals from `r methods$min_sf` cycles/pixel to
`r methods$max_sf` cycles/pixel. A geometric progression was used because high
spatial frequencies are harder to distinguish than low spatial frequencies.

(ref:gabors) Sampled space of possible gabor patches. Gabor patches varied
in orientation and spatial frequency.

```{r gabors, fig.cap="(ref:gabors)"}
draw_image("SimpleHillGems", package = "gems")
```

### Solution landscapes {-}

We created three different landscapes. There were two different training
landscapes, and one test landscape. The training landscapes were constructed so
that the value of a gem was determined completely by one dimension (either
orientation or spatial frequency) and not influenced by the other dimension.
Values in the test landscape were determined by both orientation and spatial
frequency. The training and test landscapes are shown in Fig.
\@ref(fig:landscapes).

(ref:landscapes) Participants assigned to the orientation or bar width
condition completed the training trials on the corresponding landscape.
All participants completed the test trials on the same landscape.

```{r landscapes, fig.width=8, fig.cap="(ref:landscapes)"}
gridExtra::grid.arrange(
  orientation_bias_landscape,
  spatial_frequency_bias_landscape,
  simple_hill_landscape,
  nrow = 1
)
```

### Post experiment survey {-}

After finishing the main experiment, participants completed a short survey.
We asked the participants about the instructions they received, how they
approached the experiment, and to what extent they thought the gems and
scores were random. We were particularly interested in if the
participants felt they were moving around the solution landscape.
The questions are listed in Table \@ref(tab:survey-questions).

(ref:survey-questions) Questions asked in the post-experiment survey.

```{r survey-questions, results='asis'}
data("Survey")
data_frame(question_text = colnames(Survey)) %>%
  mutate(question_id = c("timestamp", "subj_id", "computer", "age", "gender", paste0("Q", 1:9))) %>%
  filter(grepl("Q", question_id)) %>%
  select(`#` = question_id, `Text` = question_text) %>%
  kable(caption="(ref:survey-questions)") %>%
  column_spec(2, width = "45em")
```

## Procedure {-}

Participants played a computer game where they pretended to be a space explorer
who travels to another planet to collect precious gems. The goal of the game
was to discover which gems are valued the most.

Participants completed a block of 30 training trials followed by four blocks
of 40 test trials. After completing all trials, participants were given
a post-experiment survey. The experiment took around 30 minutes
to complete.

### Training {-}

Participants were randomly assigned to one of two training conditions. In the
orientation condition, participants were told that the value of each gem
was determined by the orientation of the stripes. In the bar width condition,
they were told the value was determined by the width of the bars.

```{r training, fig.width=8}
gridExtra::grid.arrange(
  crotchet::read_image("training_orientation", package = "gems"),
  crotchet::read_image("training_spatial_frequency", package = "gems"),
  nrow = 1
)
```

After reading the training instructions, participants completed a block of 30
training trials on a training landscape corresponding to their
instructions condition. For example, a participant who was instructed to pay
attention to bar width completed the training trials on the landscape that was
biased so that the values of the gems were dependent completely on spatial
frequency and not on orientation.

For the training trials, after each choice, participants were shown the values
of all the gems in the display, and had to click on the most valuable
gem to continue to the next trial. This second response was to encourage
participants to learn which gabors were the most valuable. If the participant
correctly selected the most valuable gem, they were told to
click on the gem they selected again.

### Test {-}

After completing the training trials, participants completed four blocks of 40
trials. All test trials were conducted on the test landscape, described above.
Participants traversed the same landscape four times.

First generation participants started off at the origin for each block. Second
generation participants started off at the location of a randomly selected first
generation participant after 20 trials. First and second generation participants
were yoked over blocks such that second generation participants inherited from
the same first generation participant at the start of each new block.

## Participants {-}

Participants were undergraduates at the University of Wisconsin-Madison who
completed the experiment in exchange for course credit. We decided to collect
data for 40 first generation participants, and 80 second generation
participants. There were twice as many second generation participants because
each first generation participant was yoked to two second generation
participants, one in each training condition.

# Results {-}

```{r results}
```

## Training {-}

First and second generation participants completed the same training procedure.
In the training procedure, participants traversed either the oriention bias landscape
or the spatial frequency bias landscape. As expected, participants in either training
condition moved through the same stimulus space in orthogonal directions
(Fig. \@ref(fig:gems-training)).

(ref:gems-training) Results of training procedure. Participants were randomly assigned to either
the orientation or the spatial frequency condition.

```{r gems-training, fig.width=10, fig.height=4, fig.cap="(ref:gems-training)"}
gridExtra::grid.arrange(
  training_positions_plot + ggtitle("A. Position"),
  training_distance_plot + ggtitle("B. Distance"),
  training_scores_plot + ggtitle("C. Score"),
  nrow = 1
)
```

(ref:gems-training-sensitivities) Sensitivity to stimulus dimensions.

```{r gems-training-sensitivities, fig.width=8, fig.height=3, fig.cap="(ref:gems-training-sensitivities)"}
gridExtra::grid.arrange(
  score_sensitivity_plot +
    theme(legend.position = c(0.4, 0.8)) +
    ggtitle("A. Score"),
  orientation_sensitivity_plot +
    theme(legend.position = "none") +
    ggtitle("B. Orientation"),
  spatial_frequency_sensitivity_plot +
    theme(legend.position = "none") +
    ggtitle("C. Spatial frequency"),
  nrow = 1
)
```

## First generation {-}

(ref:gen1-results) Results of first generation problem solvers. Each line is a
participant. **A. Position** on the solution landscape. **B. Distance** between current location and 2D peak. **C. Score** over trials. 

```{r gen1-results, fig.width=8, fig.height=10, fig.cap="(ref:gen1-results)"}
gridExtra::grid.arrange(
  gen1_positions_plot + ggtitle("A. Position"),
  gen1_distance_plot + ggtitle("B. Distance"),
  gen1_scores_plot + ggtitle("C. Score"),
  nrow = 3
)
```

(ref:gen1-final-scores) First generation performance by block.

```{r gen1-final-scores, fig.width=6, fig.cap="(ref:gen1-final-scores)"}
gridExtra::grid.arrange(
  gen1_final_scores_plot + ggtitle("A. Final scores"),
  gen1_final_distances_plot + ggtitle("B. Distance to peak"),
  nrow = 1
)
```

## Second generation {-}

(ref:gen2-results) Second generation results.

```{r gen2-results, fig.width=8, fig.height=10, fig.cap="(ref:gen2-results)"}
gridExtra::grid.arrange(
  gen2_positions_plot + ggtitle("A. Position"),
  gen2_distance_plot + ggtitle("B. Distance"),
  gen2_scores_plot + ggtitle("C. Score"),
  nrow = 3
)
```

(ref:gen2-final-scores) Second generation performance by block.

```{r gen2-final-scores, fig.width=6, fig.cap="(ref:gen2-final-scores)"}
gridExtra::grid.arrange(
  gen2_final_scores_plot + ggtitle("A. Final scores"),
  gen2_final_distances_plot + ggtitle("B. Distance to peak"),
  nrow = 1
)
```

## Strategies {-}

```{r gems-generation2, fig.width=8}
Gems %>%
  filter(subj_id == "GEMS120" | ancestor_id == "GEMS120",
         landscape_ix != 0, team_trial <= 40) %>%
  ggplot() +
    aes(team_trial, score, group = subj_id, color = instructions) +
    geom_line(aes(linetype = factor(generation))) +
    facet_wrap("landscape_ix", nrow = 1) +
    t_$theme +
    theme(legend.position = "bottom")
```

(ref:strategies) Hill climbing performance. **A. Scores** correspond to heights
on the landscape, and **C. Distances** correspond to Euclidean distances between
current location and peak in the landscape. **B.** and **D.** show these same
measures controlling for starting position.

```{r strategies, fig.width=7, fig.height=7, fig.cap="(ref:strategies)"}
gridExtra::grid.arrange(
  strategies_scores_plot + ggtitle("A. Final score"),
  strategies_relative_scores_plot + ggtitle("B. Relative score"),
  strategies_distance_plot + ggtitle("C. Distance to peak"), 
  strategies_relative_distance_plot + ggtitle("D. Relative distance"),
  nrow = 2
)
```

# Discussion {-}
